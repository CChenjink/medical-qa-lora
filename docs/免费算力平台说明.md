# 免费算力平台说明

本文档介绍如何使用免费 GPU 平台进行模型训练。

## 平台对比

| 平台 | GPU | 显存 | 时长限制 | 优点 | 缺点 |
|------|-----|------|----------|------|------|
| Google Colab | T4 | 15GB | 12h/次 | 易用，免费 | 会话断开 |
| Kaggle | P100 | 16GB | 30h/周 | 性能好，时长多 | 需要验证 |
| AutoDL | 3090/A5000 | 24GB | 按时计费 | 国内快，配置灵活 | 需付费 |

---

## Google Colab

### 优势
- 完全免费
- 无需配置环境
- 与 Google Drive 集成
- 支持 Jupyter Notebook

### 使用步骤

#### 1. 访问 Colab
- 网址：https://colab.research.google.com
- 使用 Google 账号登录

#### 2. 启用 GPU
```
菜单栏 -> 运行时 -> 更改运行时类型 -> 硬件加速器 -> GPU
```

#### 3. 检查 GPU
```python
!nvidia-smi
```

#### 4. 挂载 Google Drive（可选）
```python
from google.colab import drive
drive.mount('/content/drive')
```

#### 5. 克隆项目
```bash
!git clone <your-repo-url>
%cd project
```

#### 6. 安装依赖
```bash
!pip install -r requirements.txt
```

#### 7. 运行训练
```bash
!python train.py --config configs/lora_20k.yaml
```

### 注意事项

1. **会话限制**：空闲 90 分钟会断开
2. **保存模型**：定期保存到 Google Drive
```python
!cp -r outputs/lora_20k /content/drive/MyDrive/models/
```
3. **避免刷屏**：使用 `%%capture` 捕获输出
```python
%%capture
!python train.py --config configs/lora_20k.yaml
```

### 保持连接（可选）

在浏览器控制台运行：
```javascript
function ClickConnect(){
  console.log("Clicked on connect button"); 
  document.querySelector("colab-connect-button").click()
}
setInterval(ClickConnect, 60000)
```

---

## Kaggle Notebooks

### 优势
- GPU 性能更好（P100）
- 时长配额更多（30h/周）
- 支持后台运行
- 可以直接使用 Kaggle 数据集

### 使用步骤

#### 1. 访问 Kaggle
- 网址：https://www.kaggle.com/code
- 注册并验证手机号

#### 2. 创建 Notebook
- 点击 "New Notebook"
- 右侧设置 -> Accelerator -> GPU T4 x2 或 P100

#### 3. 上传代码
- 可以上传文件或从 GitHub 导入
- 或直接在 Notebook 中编写代码

#### 4. 运行训练
```bash
!pip install -r requirements.txt
!python train.py --config configs/lora_20k.yaml
```

### 注意事项

1. **GPU 配额**：每周 30 小时
2. **查看配额**：Settings -> Account -> GPU Quota
3. **后台运行**：关闭浏览器也继续运行
4. **保存输出**：输出会自动保存

---

## AutoDL（国内平台）

### 优势
- 国内访问快
- GPU 选择多（3090, A5000, A6000）
- 配置灵活
- 支持 SSH 连接

### 使用步骤

#### 1. 注册账号
- 网址：https://www.autodl.com
- 新用户送免费算力

#### 2. 创建实例
- 选择镜像：PyTorch 2.0
- 选择 GPU：RTX 3090 (24GB)
- 选择区域：就近选择

#### 3. 连接实例
- 使用 JupyterLab 或 SSH
- 上传代码和数据

#### 4. 运行训练
```bash
cd /root/autodl-tmp
git clone <your-repo>
cd project
pip install -r requirements.txt
python train.py --config configs/lora_20k.yaml
```

### 省钱技巧

1. **使用抢占式实例**：更便宜（约 1-2 元/小时）
2. **训练完及时关机**：避免浪费
3. **数据集提前下载**：节省时间
4. **使用学生认证**：获得优惠

---

## 其他平台

### Hugging Face Spaces
- 免费 CPU/GPU
- 适合部署 Demo
- 不适合训练

### Paperspace Gradient
- 免费 GPU（有限额）
- 类似 Colab
- 需要信用卡验证

### 阿里云 PAI-DSW
- 新用户有免费试用
- 国内访问快
- 需要实名认证

---

## 最佳实践

### 1. 代码优化

```python
# 使用混合精度训练
training_args = TrainingArguments(
    fp16=True,  # 节省显存
    gradient_checkpointing=True,  # 进一步节省显存
)

# 使用梯度累积
training_args = TrainingArguments(
    per_device_train_batch_size=2,
    gradient_accumulation_steps=8,  # 等效 batch_size=16
)
```

### 2. 数据管理

- 使用小数据集快速验证代码
- 数据预处理在本地完成
- 使用 Hugging Face Datasets 缓存

### 3. 模型保存

```python
# 定期保存检查点
training_args = TrainingArguments(
    save_steps=500,
    save_total_limit=3,  # 只保留最近 3 个
)

# 保存到云端
import shutil
shutil.copytree('outputs', '/content/drive/MyDrive/outputs')
```

### 4. 监控训练

```python
# 使用 TensorBoard
from torch.utils.tensorboard import SummaryWriter
writer = SummaryWriter('logs')

# 或使用 Weights & Biases
import wandb
wandb.init(project="medical-qa")
```

---

## 推荐配置

### 实验建议

- **20k 数据实验**：使用 Google Colab（训练时间 2-3小时）
- **50k 数据实验**：使用 Kaggle Notebooks（训练时间 5-6小时）
- **100k 数据实验**：使用 Kaggle 或 AutoDL（训练时间 10-12小时）
- **QLoRA 实验**：显存需求更低，所有平台都可以运行

### 时间规划

- **第1周**：环境搭建，数据准备（所有平台）
- **第2周**：小规模实验（Colab，1-2小时/次）
- **第3周**：大规模实验（Kaggle，2-3小时/次）
- **第4周**：整理结果，撰写报告

---

## 常见问题

### Q: Colab 会话断开怎么办？
A: 使用保持连接脚本，或定期保存模型到 Google Drive

### Q: 显存不足怎么办？
A: 
- 减小 batch size
- 使用 QLoRA (4-bit 量化)
- 启用 gradient_checkpointing
- 减小模型 max_length

### Q: 训练太慢怎么办？
A:
- 使用更小的数据集测试
- 减少训练轮数
- 使用 Kaggle P100（性能更好）

### Q: 如何在多个平台间迁移？
A:
- 使用 Git 管理代码
- 数据集上传到 Hugging Face
- 模型保存到云盘

---

## 总结

- **快速测试**：使用 Colab（免费，易用）
- **长时间训练**：使用 Kaggle（30h/周）
- **国内用户**：使用 AutoDL（访问快，但需付费）
- **建议**：先在 Colab 测试代码，确认无误后再进行长时间训练
