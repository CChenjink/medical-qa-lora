# 使用指南

本文档提供详细的操作步骤和命令说明。

## 环境准备

### 1. 安装依赖

```bash
pip install -r requirements.txt
```

### 2. 下载模型

```bash
# 方式1：从 ModelScope 下载（国内推荐）
python scripts/download_model.py \
    --model_name Qwen/Qwen2.5-3B-Instruct \
    --source modelscope \
    --save_dir ./models

# 方式2：从 Hugging Face 下载
python scripts/download_model.py \
    --model_name Qwen/Qwen2.5-3B-Instruct \
    --source huggingface \
    --save_dir ./models
```

### 3. 准备数据

```bash
# 下载数据集
python scripts/download_data.py

# 或创建示例数据（用于快速测试）
python scripts/download_data.py --create_sample

# 预处理数据
python scripts/preprocess_data.py \
    --raw_data ./data/raw/medical_qa.json \
    --output_dir ./data/processed \
    --max_samples 100000

# 准备不同规模数据集（10k/20k/40k/60k）
python scripts/prepare_data_splits.py \
    --train_file ./data/processed/train.json \
    --output_dir ./data/processed
```

---

## 训练模型

### LoRA 微调

```bash
# LoRA 10k
python train.py --config configs/lora_10k.yaml

# LoRA 20k
python train.py --config configs/lora_20k.yaml

# LoRA 40k
python train.py --config configs/lora_40k.yaml

# LoRA 60k
python train.py --config configs/lora_60k.yaml
```

### QLoRA 微调

```bash
# QLoRA 10k
python train.py --config configs/qlora_10k.yaml

# QLoRA 20k
python train.py --config configs/qlora_20k.yaml

# QLoRA 40k
python train.py --config configs/qlora_40k.yaml

# QLoRA 60k
python train.py --config configs/qlora_60k.yaml
```

### 恢复训练

```bash
python train.py \
    --config configs/lora_10k.yaml \
    --resume_from_checkpoint outputs/lora_10k/checkpoint-600
```

---

## 评估模型

### Baseline 评估

```bash
python evaluate.py \
    --model_path ./models/qwen2.5-3b \
    --test_file ./data/processed/test.json \
    --output_file ./outputs/baseline/eval_results.json
```

### LoRA 模型评估

```bash
python evaluate.py \
    --model_path outputs/lora_10k/checkpoint-best \
    --base_model_path models/qwen2.5-3b \
    --test_file ./data/processed/test.json \
    --output_file outputs/lora_10k/eval_results.json
```

### QLoRA 模型评估

```bash
python evaluate.py \
    --model_path outputs/qlora_10k/checkpoint-best \
    --base_model_path models/qwen2.5-3b \
    --test_file ./data/processed/test.json \
    --output_file outputs/qlora_10k/eval_results.json
```

### 限制评估样本数（快速测试）

```bash
python evaluate.py \
    --model_path outputs/lora_10k/checkpoint-best \
    --base_model_path models/qwen2.5-3b \
    --max_samples 100
```

---

## 交互测试

### 基本使用

```bash
python inference.py \
    --model_path outputs/lora_10k/checkpoint-best \
    --base_model_path models/qwen2.5-3b
```

### 自定义指令

```bash
python inference.py \
    --model_path outputs/lora_10k/checkpoint-best \
    --base_model_path models/qwen2.5-3b \
    --instruction "你是一个专业的医疗助手"
```

### 交互命令

- 输入问题开始对话
- 输入 `quit` 或 `exit` 退出
- 输入 `clear` 清屏

---

## 汇总结果

```bash
# 汇总所有实验结果
python scripts/summarize_results.py

# 输出：
# - outputs/summary/results_summary.csv
# - outputs/summary/data_scale_comparison.png
```

---

## 配置文件说明

### LoRA 配置示例

```yaml
# configs/lora_10k.yaml
model_name_or_path: "Qwen/Qwen2.5-3B-Instruct"

lora_config:
  r: 8                    # LoRA rank
  lora_alpha: 32          # LoRA alpha
  target_modules:         # 目标模块
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
  lora_dropout: 0.1

training_args:
  output_dir: "./outputs/lora_10k"
  num_train_epochs: 3
  per_device_train_batch_size: 4
  learning_rate: 1.0e-4
  warmup_ratio: 0.1

data_config:
  train_file: "./data/processed/train_10k.json"
  validation_file: "./data/processed/dev.json"
  test_file: "./data/processed/test.json"
  max_samples: 10000
```

### QLoRA 配置示例

```yaml
# configs/qlora_10k.yaml
model_name_or_path: "Qwen/Qwen2.5-3B-Instruct"

quantization_config:
  load_in_4bit: true
  bnb_4bit_compute_dtype: "float16"
  bnb_4bit_use_double_quant: true
  bnb_4bit_quant_type: "nf4"

lora_config:
  r: 8
  lora_alpha: 32
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"

training_args:
  output_dir: "./outputs/qlora_10k"
  per_device_train_batch_size: 8  # QLoRA 可以用更大的 batch size
  warmup_ratio: 0.1
```

---

## 常见问题

### Q: 显存不足怎么办？

**A**: 
1. 使用 QLoRA（4-bit 量化）
2. 减小 `per_device_train_batch_size`
3. 增大 `gradient_accumulation_steps`
4. 减小 `max_source_length` 和 `max_target_length`

### Q: 训练速度慢怎么办？

**A**:
1. 使用更小的数据集测试（10k）
2. 减少 `num_train_epochs`
3. 启用 `fp16=true`
4. 使用更好的 GPU

### Q: 如何查看训练日志？

**A**:
```bash
# 使用 TensorBoard
tensorboard --logdir outputs/lora_10k/logs

# 或查看日志文件
cat outputs/lora_10k/logs/events.out.tfevents.*
```

---

## 目录结构

训练后的目录结构：

```
outputs/
├── lora_10k/
│   ├── checkpoint-600/
│   ├── checkpoint-1200/
│   ├── checkpoint-best/
│   ├── logs/
│   └── eval_results.json
├── lora_20k/
├── lora_40k/
├── lora_60k/
├── qlora_10k/
├── qlora_20k/
├── qlora_40k/
├── qlora_60k/
└── summary/
    ├── results_summary.csv
    └── data_scale_comparison.png
```

---

## 下一步

- 查看 [configs/README.md](../configs/README.md) 了解配置文件详情
- 查看 [免费算力平台说明.md](免费算力平台说明.md) 使用免费 GPU
- 遇到问题查看项目 README.md 的常见问题部分
