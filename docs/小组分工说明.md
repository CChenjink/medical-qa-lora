# 小组分工说明

## 项目概述

- **基座模型**：Qwen2.5-4B-Instruct
- **任务**：中文医疗问答系统微调
- **核心实验**：Baseline + LoRA(1k/5k/10k) + QLoRA(1k/5k/10k)
- **时间**：4周

---

## 成员分工

### 👤 成员1：项目负责人 + Baseline评估

**职责**：
- 项目整体协调
- 搭建评估框架
- Baseline 性能测试
- 最终报告整合

**具体任务**：
1. 环境搭建和依赖安装
2. 下载 Qwen2.5-4B 模型
3. 数据集下载和预处理
4. 测试原始模型性能（Baseline）
5. 建立评估指标体系
6. 汇总所有实验结果
7. 撰写实验报告框架

**命令**：
```bash
# 环境准备
pip install -r requirements.txt
python scripts/download_model.py --model_name Qwen/Qwen2.5-4B-Instruct
python scripts/download_data.py
python scripts/preprocess_data.py
python scripts/prepare_data_splits.py

# Baseline 评估
python evaluate.py \
    --model_path ./models/qwen2.5-4b \
    --test_file ./data/processed/test.json \
    --output_file ./outputs/baseline/eval_results.json
```

**交付物**：
- ✅ 完整的项目环境
- ✅ Baseline 评估结果
- ✅ 评估框架代码
- ✅ 实验报告初稿

**时间安排**：
- 第1周：环境搭建 + Baseline
- 第2-3周：协助其他成员
- 第4周：报告整合

---

### 👤 成员2：LoRA 微调（1k + 5k 数据）

**职责**：
- LoRA 方法实现
- 小规模数据实验
- 数据规模影响分析（前半部分）

**具体任务**：
1. 配置 LoRA 参数
2. 训练 LoRA-1k 模型
3. 训练 LoRA-5k 模型
4. 评估两个模型性能
5. 对比 1k vs 5k 效果
6. 记录训练过程和资源占用

**命令**：
```bash
# LoRA 1k
python train.py --config configs/lora_1k.yaml
python evaluate.py \
    --model_path outputs/lora_1k/checkpoint-best \
    --base_model_path models/qwen2.5-4b \
    --output_file outputs/lora_1k/eval_results.json

# LoRA 5k
python train.py --config configs/lora_5k.yaml
python evaluate.py \
    --model_path outputs/lora_5k/checkpoint-best \
    --base_model_path models/qwen2.5-4b \
    --output_file outputs/lora_5k/eval_results.json
```

**交付物**：
- ✅ LoRA-1k 训练好的模型
- ✅ LoRA-5k 训练好的模型
- ✅ 训练日志和曲线
- ✅ 1k vs 5k 对比分析

**时间安排**：
- 第1周：环境熟悉 + LoRA-1k
- 第2周：LoRA-5k
- 第3周：评估和分析
- 第4周：撰写报告章节

---

### 👤 成员3：LoRA 微调（10k 数据）+ 数据规模总结

**职责**：
- 大规模 LoRA 训练
- 数据规模影响总结
- LoRA 方法总结

**具体任务**：
1. 训练 LoRA-10k 模型
2. 评估模型性能
3. 汇总 1k/5k/10k 数据规模实验
4. 绘制数据规模-性能曲线
5. 分析最优数据量
6. 总结 LoRA 方法优缺点

**命令**：
```bash
# LoRA 10k
python train.py --config configs/lora_10k.yaml
python evaluate.py \
    --model_path outputs/lora_10k/checkpoint-best \
    --base_model_path models/qwen2.5-4b \
    --output_file outputs/lora_10k/eval_results.json

# 汇总结果
python scripts/summarize_results.py
```

**交付物**：
- ✅ LoRA-10k 训练好的模型
- ✅ 数据规模对比图表
- ✅ 最优数据量分析
- ✅ LoRA 方法总结报告

**时间安排**：
- 第1-2周：LoRA-10k 训练
- 第3周：数据规模分析
- 第4周：撰写报告章节

---

### 👤 成员4：QLoRA 微调（1k + 5k 数据）

**职责**：
- QLoRA 方法实现
- 小规模量化实验
- QLoRA 数据规模分析（前半部分）

**具体任务**：
1. 配置 QLoRA（4-bit 量化）
2. 训练 QLoRA-1k 模型
3. 训练 QLoRA-5k 模型
4. 评估两个模型性能
5. 对比 QLoRA 1k vs 5k
6. 记录显存占用和训练速度
7. 与 LoRA 对比效率

**命令**：
```bash
# QLoRA 1k
python train.py --config configs/qlora_1k.yaml
python evaluate.py \
    --model_path outputs/qlora_1k/checkpoint-best \
    --base_model_path models/qwen2.5-4b \
    --output_file outputs/qlora_1k/eval_results.json

# QLoRA 5k
python train.py --config configs/qlora_5k.yaml
python evaluate.py \
    --model_path outputs/qlora_5k/checkpoint-best \
    --base_model_path models/qwen2.5-4b \
    --output_file outputs/qlora_5k/eval_results.json
```

**交付物**：
- ✅ QLoRA-1k 训练好的模型
- ✅ QLoRA-5k 训练好的模型
- ✅ 显存和速度对比数据
- ✅ QLoRA vs LoRA 效率分析

**时间安排**：
- 第1周：环境熟悉 + QLoRA-1k
- 第2周：QLoRA-5k
- 第3周：效率对比分析
- 第4周：撰写报告章节

---

### 👤 成员5：QLoRA 微调（10k 数据）+ 方法对比总结

**职责**：
- 大规模 QLoRA 训练
- LoRA vs QLoRA 全面对比
- 实验报告撰写

**具体任务**：
1. 训练 QLoRA-10k 模型
2. 评估模型性能
3. 汇总所有 QLoRA 实验
4. 全面对比 LoRA vs QLoRA
5. 分析适用场景
6. 撰写实验报告主体部分

**命令**：
```bash
# QLoRA 10k
python train.py --config configs/qlora_10k.yaml
python evaluate.py \
    --model_path outputs/qlora_10k/checkpoint-best \
    --base_model_path models/qwen2.5-4b \
    --output_file outputs/qlora_10k/eval_results.json

# 汇总结果
python scripts/summarize_results.py
```

**交付物**：
- ✅ QLoRA-10k 训练好的模型
- ✅ LoRA vs QLoRA 全面对比
- ✅ 方法选择建议
- ✅ 实验报告主体章节

**时间安排**：
- 第1-2周：QLoRA-10k 训练
- 第3周：方法对比分析
- 第4周：撰写报告主体

---

## 实验矩阵

| 实验编号 | 方法 | 数据量 | 负责人 | 输出目录 | 预计时间 |
|---------|------|--------|--------|----------|----------|
| EXP-00 | Baseline | - | 成员1 | outputs/baseline | 0.5h |
| EXP-01 | LoRA | 1k | 成员2 | outputs/lora_1k | 0.5h |
| EXP-02 | LoRA | 5k | 成员2 | outputs/lora_5k | 1h |
| EXP-03 | LoRA | 10k | 成员3 | outputs/lora_10k | 2h |
| EXP-04 | QLoRA | 1k | 成员4 | outputs/qlora_1k | 0.5h |
| EXP-05 | QLoRA | 5k | 成员4 | outputs/qlora_5k | 1h |
| EXP-06 | QLoRA | 10k | 成员5 | outputs/qlora_10k | 2h |

---

## 协作流程（4周计划）

### 第1周：环境搭建和基础实验

**所有成员**：
```bash
# 安装依赖
pip install -r requirements.txt

# 下载模型（成员1负责，其他人复用）
python scripts/download_model.py \
    --model_name Qwen/Qwen2.5-4B-Instruct \
    --source modelscope

# 下载和预处理数据
python scripts/download_data.py
python scripts/preprocess_data.py

# 准备不同规模数据集
python scripts/prepare_data_splits.py
```

**成员1**：Baseline 评估  
**成员2、4**：开始 1k 数据训练

### 第2周：核心实验

**成员2**：LoRA-5k 训练  
**成员3**：LoRA-10k 训练  
**成员4**：QLoRA-5k 训练  
**成员5**：QLoRA-10k 训练

### 第3周：评估和分析

**所有成员**：
- 完成各自模型评估
- 记录实验数据（ROUGE分数、训练时间、显存占用）
- 进行对比分析

**成员3**：数据规模影响分析  
**成员5**：LoRA vs QLoRA 对比

### 第4周：报告撰写

**成员1**：整合所有章节，撰写摘要和结论  
**成员2-5**：各自撰写负责部分，准备图表和案例

---

## 沟通与协作

### 沟通渠道
- **微信群**：日常问题讨论
- **GitHub**：代码和技术问题
- **云盘**：模型和数据共享

### 协作建议
1. **及时沟通**：遇到问题立即讨论
2. **代码规范**：遵循项目代码风格
3. **实验记录**：详细记录所有参数和结果
4. **备份数据**：重要模型及时备份
5. **时间管理**：避免最后一周赶工

---

## 注意事项

1. 所有成员第1周完成环境搭建
2. 记录实验结果：ROUGE分数、训练时间、显存占用
3. 定期同步进度，及时解决问题
4. 保存训练日志和模型检查点
5. 准备好案例用于报告展示
