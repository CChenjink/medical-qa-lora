# å®éªŒè¯´æ˜æ–‡æ¡£

## é¡¹ç›®æ¦‚è¿°

- **åŸºåº§æ¨¡å‹**ï¼šQwen2.5-3B-Instruct
- **ä»»åŠ¡**ï¼šä¸­æ–‡åŒ»ç–—é—®ç­”ç³»ç»Ÿå¾®è°ƒ
- **æ ¸å¿ƒå®éªŒ**ï¼šç ”ç©¶è®­ç»ƒæ•°æ®è§„æ¨¡å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“
- **æ•°æ®è§„æ¨¡**ï¼š20k / 50k / 100k
- **å¾®è°ƒæ–¹æ³•**ï¼šLoRA / QLoRA

---

## å®éªŒè®¾è®¡

æœ¬é¡¹ç›®æ—¨åœ¨ç ”ç©¶è®­ç»ƒæ•°æ®è§„æ¨¡å¯¹å¤§æ¨¡å‹å¾®è°ƒæ•ˆæœçš„å½±å“ï¼Œè®¾è®¡äº†ä»¥ä¸‹å®éªŒï¼š

### å®éªŒçŸ©é˜µ

| å®éªŒç¼–å· | æ–¹æ³• | æ•°æ®é‡ | é…ç½®æ–‡ä»¶ | è¾“å‡ºç›®å½• | é¢„è®¡æ—¶é—´ (T4) |
|---------|------|--------|----------|----------|---------------|
| EXP-01 | LoRA | 20k | lora_20k.yaml | outputs/lora_20k | ~1-1.5h |
| EXP-02 | LoRA | 50k | lora_50k.yaml | outputs/lora_50k | ~3-4h |
| EXP-03 | LoRA | 100k | lora_100k.yaml | outputs/lora_100k | ~6-7h |
| EXP-04 | QLoRA | 20k | qlora_20k.yaml | outputs/qlora_20k | ~1.5-2h |
| EXP-05 | QLoRA | 50k | qlora_50k.yaml | outputs/qlora_50k | ~4-5h |
| EXP-06 | QLoRA | 100k | qlora_100k.yaml | outputs/qlora_100k | ~8-9h |

### å®éªŒç›®æ ‡

1. **æ•°æ®è§„æ¨¡å½±å“**ï¼šå¯¹æ¯” 20kã€50kã€100k ä¸‰ç§æ•°æ®è§„æ¨¡å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“
2. **æ–¹æ³•å¯¹æ¯”**ï¼šå¯¹æ¯” LoRA å’Œ QLoRA ä¸¤ç§å¾®è°ƒæ–¹æ³•çš„æ•ˆæœå·®å¼‚
3. **æ•ˆç‡åˆ†æ**ï¼šåˆ†æè®­ç»ƒæ—¶é—´ã€æ˜¾å­˜å ç”¨ç­‰èµ„æºæ¶ˆè€—
4. **æœ€ä¼˜é…ç½®**ï¼šæ‰¾å‡ºæ€§ä»·æ¯”æœ€é«˜çš„æ•°æ®è§„æ¨¡å’Œå¾®è°ƒæ–¹æ³•

---

## ç¯å¢ƒå‡†å¤‡

### 1. å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

### 2. ä¸‹è½½æ¨¡å‹

```bash
# ä» ModelScope ä¸‹è½½ï¼ˆå›½å†…æ¨èï¼‰
python scripts/download_model.py \
    --model_name Qwen/Qwen2.5-3B-Instruct \
    --source modelscope \
    --save_dir ./models

# æˆ–ä» Hugging Face ä¸‹è½½
python scripts/download_model.py \
    --model_name Qwen/Qwen2.5-3B-Instruct \
    --source huggingface \
    --save_dir ./models
```

### 3. å‡†å¤‡æ•°æ®

```bash
# ä¸‹è½½æ•°æ®é›†
python scripts/download_data.py

# é¢„å¤„ç†æ•°æ®
python scripts/preprocess_data.py

# å‡†å¤‡ä¸åŒè§„æ¨¡æ•°æ®é›†ï¼ˆ20k/50k/100kï¼‰
python scripts/prepare_data_splits.py
```

---

## å®éªŒæ‰§è¡Œ

### LoRA å®éªŒ

```bash
# å®éªŒ1ï¼šLoRA 20k
python train.py --config configs/lora_20k.yaml
python evaluate.py \
    --model_path outputs/lora_20k/checkpoint-best \
    --base_model_path models/Qwen_Qwen2.5-3B-Instruct \
    --output_file outputs/lora_20k/eval_results.json

# å®éªŒ2ï¼šLoRA 50k
python train.py --config configs/lora_50k.yaml
python evaluate.py \
    --model_path outputs/lora_50k/checkpoint-best \
    --base_model_path models/Qwen_Qwen2.5-3B-Instruct \
    --output_file outputs/lora_50k/eval_results.json

# å®éªŒ3ï¼šLoRA 100k
python train.py --config configs/lora_100k.yaml
python evaluate.py \
    --model_path outputs/lora_100k/checkpoint-best \
    --base_model_path models/Qwen_Qwen2.5-3B-Instruct \
    --output_file outputs/lora_100k/eval_results.json
```

### QLoRA å®éªŒ

```bash
# å®éªŒ4ï¼šQLoRA 20k
python train.py --config configs/qlora_20k.yaml
python evaluate.py \
    --model_path outputs/qlora_20k/checkpoint-best \
    --base_model_path models/Qwen_Qwen2.5-3B-Instruct \
    --output_file outputs/qlora_20k/eval_results.json

# å®éªŒ5ï¼šQLoRA 50k
python train.py --config configs/qlora_50k.yaml
python evaluate.py \
    --model_path outputs/qlora_50k/checkpoint-best \
    --base_model_path models/Qwen_Qwen2.5-3B-Instruct \
    --output_file outputs/qlora_50k/eval_results.json

# å®éªŒ6ï¼šQLoRA 100k
python train.py --config configs/qlora_100k.yaml
python evaluate.py \
    --model_path outputs/qlora_100k/checkpoint-best \
    --base_model_path models/Qwen_Qwen2.5-3B-Instruct \
    --output_file outputs/qlora_100k/eval_results.json
```

---

## ç»“æœæ±‡æ€»

### æ±‡æ€»æ‰€æœ‰å®éªŒç»“æœ

```bash
python scripts/summarize_results.py
```

è¾“å‡ºæ–‡ä»¶ï¼š
- `outputs/summary/results_summary.csv` - æ‰€æœ‰å®éªŒç»“æœæ±‡æ€»è¡¨
- `outputs/summary/data_scale_comparison.png` - æ•°æ®è§„æ¨¡å¯¹æ¯”å›¾
- `outputs/summary/method_comparison.png` - æ–¹æ³•å¯¹æ¯”å›¾

### è¯„ä¼°æŒ‡æ ‡

è®°å½•ä»¥ä¸‹æŒ‡æ ‡ç”¨äºå¯¹æ¯”åˆ†æï¼š

| æŒ‡æ ‡ | è¯´æ˜ |
|------|------|
| ROUGE-1 | å•è¯çº§åˆ«çš„å¬å›ç‡ |
| ROUGE-2 | åŒè¯çº§åˆ«çš„å¬å›ç‡ |
| ROUGE-L | æœ€é•¿å…¬å…±å­åºåˆ— |
| BLEU | æœºå™¨ç¿»è¯‘è¯„ä¼°æŒ‡æ ‡ |
| è®­ç»ƒæ—¶é—´ | å®Œæ•´è®­ç»ƒæ‰€éœ€æ—¶é—´ |
| æ˜¾å­˜å ç”¨ | å³°å€¼æ˜¾å­˜ä½¿ç”¨é‡ |
| æ¨ç†é€Ÿåº¦ | æ¯ç§’å¤„ç†çš„æ ·æœ¬æ•° |

---

## å®éªŒæ—¶é—´è§„åˆ’

### ç¬¬1å‘¨ï¼šç¯å¢ƒæ­å»ºå’Œå°è§„æ¨¡å®éªŒ

- ç¯å¢ƒå‡†å¤‡å’Œä¾èµ–å®‰è£…
- æ•°æ®ä¸‹è½½å’Œé¢„å¤„ç†
- è¿è¡Œ 20k æ•°æ®å®éªŒï¼ˆLoRA + QLoRAï¼‰
- éªŒè¯å®éªŒæµç¨‹

### ç¬¬2å‘¨ï¼šä¸­è§„æ¨¡å’Œå¤§è§„æ¨¡å®éªŒ

- è¿è¡Œ 50k æ•°æ®å®éªŒï¼ˆLoRA + QLoRAï¼‰
- è¿è¡Œ 100k æ•°æ®å®éªŒï¼ˆLoRA + QLoRAï¼‰
- å¯¹æ¯”ä¸åŒæ•°æ®è§„æ¨¡çš„æ€§èƒ½å·®å¼‚

### ç¬¬3å‘¨ï¼šå®éªŒå®Œæˆå’Œç»“æœæ±‡æ€»

- å®Œæˆæ‰€æœ‰å®éªŒ
- æ±‡æ€»å®éªŒç»“æœ
- åˆæ­¥åˆ†ææ•°æ®è§„æ¨¡å½±å“

### ç¬¬4å‘¨ï¼šåˆ†æå’ŒæŠ¥å‘Š

- æ•°æ®è§„æ¨¡å½±å“åˆ†æ
- LoRA vs QLoRA æ–¹æ³•å¯¹æ¯”
- ç»˜åˆ¶å¯¹æ¯”å›¾è¡¨
- æ’°å†™å®éªŒæŠ¥å‘Š

---

## èµ„æºéœ€æ±‚

### ç¡¬ä»¶è¦æ±‚

| å®éªŒ | æ˜¾å­˜éœ€æ±‚ | æ¨èGPU |
|------|---------|---------|
| LoRA 20k | ~12GB | T4 / V100 |
| LoRA 50k | ~12GB | T4 / V100 |
| LoRA 100k | ~12GB | T4 / V100 |
| QLoRA 20k | ~8GB | T4 |
| QLoRA 50k | ~8GB | T4 |
| QLoRA 100k | ~8GB | T4 |

### å…è´¹ç®—åŠ›å¹³å°

1. **Google Colab**
   - å…è´¹ T4 GPUï¼ˆ15GBæ˜¾å­˜ï¼‰
   - æ¯æ¬¡12å°æ—¶ä½¿ç”¨æ—¶é—´
   - é€‚åˆ 20k å’Œ 50k å®éªŒ

2. **Kaggle Notebooks**
   - å…è´¹ P100 GPUï¼ˆ16GBæ˜¾å­˜ï¼‰
   - æ¯å‘¨30å°æ—¶ä½¿ç”¨æ—¶é—´
   - é€‚åˆæ‰€æœ‰å®éªŒ

3. **AutoDL**
   - æ–°ç”¨æˆ·æœ‰å…è´¹é¢åº¦
   - æŒ‰éœ€ä»˜è´¹
   - é€‚åˆ 100k å¤§è§„æ¨¡å®éªŒ

è¯¦è§ï¼š[å…è´¹ç®—åŠ›å¹³å°è¯´æ˜.md](å…è´¹ç®—åŠ›å¹³å°è¯´æ˜.md)

---

## æ³¨æ„äº‹é¡¹

### å®éªŒè®°å½•

æ¯ä¸ªå®éªŒéœ€è¦è®°å½•ï¼š
1. è®­ç»ƒå¼€å§‹å’Œç»“æŸæ—¶é—´
2. æœ€ç»ˆè¯„ä¼°æŒ‡æ ‡ï¼ˆROUGEã€BLEUç­‰ï¼‰
3. æ˜¾å­˜å ç”¨å³°å€¼
4. è®­ç»ƒè¿‡ç¨‹ä¸­çš„lossæ›²çº¿
5. é‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### æ•°æ®å¤‡ä»½

é‡è¦æ–‡ä»¶éœ€è¦åŠæ—¶å¤‡ä»½ï¼š
- è®­ç»ƒå¥½çš„æ¨¡å‹æ£€æŸ¥ç‚¹
- è¯„ä¼°ç»“æœJSONæ–‡ä»¶
- è®­ç»ƒæ—¥å¿—æ–‡ä»¶
- TensorBoardæ—¥å¿—

### å¸¸è§é—®é¢˜

1. **æ˜¾å­˜ä¸è¶³**ï¼šä½¿ç”¨QLoRAæˆ–å‡å°batch size
2. **è®­ç»ƒä¸­æ–­**ï¼šä½¿ç”¨`--resume_from_checkpoint`æ¢å¤è®­ç»ƒ
3. **è¯„ä¼°æ…¢**ï¼šä½¿ç”¨`--max_samples`é™åˆ¶è¯„ä¼°æ ·æœ¬æ•°
4. **ç»“æœä¸ç†æƒ³**ï¼šæ£€æŸ¥æ•°æ®è´¨é‡å’Œè¶…å‚æ•°è®¾ç½®

---

## å‚è€ƒèµ„æº

- [é¡¹ç›®ä¸» README](../README.md) - é¡¹ç›®æ•´ä½“è¯´æ˜
- [ä½¿ç”¨æŒ‡å—](ä½¿ç”¨æŒ‡å—.md) - è¯¦ç»†æ“ä½œæ­¥éª¤
- [é…ç½®æ–‡ä»¶è¯´æ˜](../configs/README.md) - é…ç½®å‚æ•°è¯¦è§£
- [å…è´¹ç®—åŠ›å¹³å°è¯´æ˜](å…è´¹ç®—åŠ›å¹³å°è¯´æ˜.md) - GPUå¹³å°ä½¿ç”¨æŒ‡å—

---

**å¼€å§‹å®éªŒ**ï¼šæŒ‰ç…§ä¸Šè¿°æ­¥éª¤ä¾æ¬¡æ‰§è¡Œï¼Œé‡åˆ°é—®é¢˜åŠæ—¶æŸ¥çœ‹æ–‡æ¡£æˆ–å¯»æ±‚å¸®åŠ© ğŸš€
